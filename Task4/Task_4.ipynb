{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b83746-4494-40e6-8f73-c06675d5d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8362ef92-bdab-4384-84e2-01ffdf0e4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('Loan_Data.csv')\n",
    "\n",
    "# Define the features and target variable\n",
    "features = ['credit_lines_outstanding', 'loan_amt_outstanding', 'total_debt_outstanding', 'income', 'years_employed']\n",
    "target = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe86d51-64dd-4f6c-891c-cd0746fbf611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quantization function using Mean Squared Error (MSE)\n",
    "def quantize_mse(series, num_buckets):\n",
    "    boundaries = np.linspace(series.min(), series.max(), num=num_buckets + 1)\n",
    "    return np.digitize(series, boundaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50cf738-9c22-4ed7-880f-af05376b5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply quantization to FICO scores using MSE\n",
    "num_buckets = 5 \n",
    "data['fico_buckets_mse'] = quantize_mse(data['fico_score'], num_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa00bd1-6aef-45e5-a320-1e2d1f3ac2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_mse = data[features + ['fico_buckets_mse']]\n",
    "y = data[target]\n",
    "X_train_mse, X_test_mse, y_train, y_test = train_test_split(X_mse, y, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5e2268-afa0-40e4-bc82-62202bd6ef99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build machine learning models (Logistic Regression) \n",
    "model_mse = LogisticRegression(solver='liblinear')\n",
    "model_mse.fit(X_train_mse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fdbf38-8e4f-4e31-b1a9-de53d4b04787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with MSE Quantization:\n",
      "Accuracy: 0.982\n",
      "Confusion Matrix:\n",
      " [[1634   21]\n",
      " [  15  330]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1655\n",
      "           1       0.94      0.96      0.95       345\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred_mse = model_mse.predict(X_test_mse)\n",
    "# Print model performance metrics for MSE method\n",
    "print(\"Model with MSE Quantization:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mse))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_mse))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3960f6-be32-4489-8640-c8f6f8db3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Log-Likelihood quantization function\n",
    "def quantize_log_likelihood(series, num_buckets):\n",
    "    min_score = series.min()\n",
    "    max_score = series.max()\n",
    "    \n",
    "    # Use the dynamic programming approach to find the boundaries and probabilities\n",
    "    # Initialize bucket boundaries and probabilities\n",
    "    boundaries = [min_score]\n",
    "    probabilities = []\n",
    "    \n",
    "    # Split the problem into subproblems\n",
    "    subproblems = [(min_score, max_score, num_buckets)]\n",
    "    \n",
    "    while subproblems:\n",
    "        # Pop the last subproblem\n",
    "        lower_bound, upper_bound, num_subbuckets = subproblems.pop()\n",
    "        \n",
    "        # Split the subproblem into subbuckets\n",
    "        subbucket_boundaries = np.linspace(lower_bound, upper_bound, num=num_subbuckets + 1)\n",
    "        \n",
    "        # Initialize subbucket statistics\n",
    "        subbucket_counts = np.zeros(num_subbuckets, dtype=int)\n",
    "        subbucket_defaults = np.zeros(num_subbuckets, dtype=int)\n",
    "        \n",
    "        for i in range(len(subbucket_boundaries) - 1):\n",
    "            lower_subbound = subbucket_boundaries[i]\n",
    "            upper_subbound = subbucket_boundaries[i + 1]\n",
    "            \n",
    "            # Calculate the number of records in the subbucket\n",
    "            subbucket_counts[i] = ((series >= lower_subbound) & (series < upper_subbound)).sum()\n",
    "            \n",
    "            # Calculate the number of defaults in the subbucket\n",
    "            subbucket_defaults[i] = ((series >= lower_subbound) & (series < upper_subbound)).sum()\n",
    "        \n",
    "        for i in range(num_subbuckets - 1):\n",
    "            num_defaults = subbucket_defaults[i]\n",
    "            num_records = subbucket_counts[i]\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if num_records == 0:\n",
    "                probability = 0.0\n",
    "            else:\n",
    "                probability = num_defaults / num_records\n",
    "            EPSILON = 1e-10  # Small positive value to avoid division by zero or taking the logarithm of zero\n",
    "\n",
    "            # Calculate the probability of default with smoothing\n",
    "            probability = (num_defaults + EPSILON) / (num_records + 2 * EPSILON)\n",
    "            # Calculate the log-likelihood for the subbucket\n",
    "            log_likelihood = num_defaults * np.log(probability) + (num_records - num_defaults) * np.log(1 - probability)\n",
    "            \n",
    "            if len(boundaries) < num_buckets:\n",
    "                boundaries.append(subbucket_boundaries[i + 1])\n",
    "                probabilities.append(probability)\n",
    "            else:\n",
    "                # Replace the last boundary if it's better\n",
    "                last_log_likelihood = probabilities[-1] * subbucket_counts[-1] * (1 - probabilities[-1])\n",
    "                if log_likelihood > last_log_likelihood:\n",
    "                    boundaries[-1] = subbucket_boundaries[i + 1]\n",
    "                    probabilities[-1] = probability\n",
    "        \n",
    "        # Divide the subproblem into two subproblems\n",
    "        for i in range(1, num_subbuckets):\n",
    "            subproblems.append((subbucket_boundaries[i - 1], subbucket_boundaries[i], 2))\n",
    "    \n",
    "    \n",
    "    # Map FICO scores to bucket indices\n",
    "    bucket_indices = np.digitize(series, boundaries) - 1\n",
    "    \n",
    "    # Assign probabilities to FICO scores based on the bucket indices\n",
    "    quantized_probabilities = [probabilities[i] for i in bucket_indices]\n",
    "    \n",
    "    return quantized_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15104937-4ec5-41da-9009-a9639dab02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# Note running this section is slow. Parallel processing my speed up the process for future projects.\n",
    "num_buckets = 5 \n",
    "data['fico_buckets_ll'] = quantize_log_likelihood(data['fico_score'], num_buckets)\n",
    "\n",
    "X_ll = data[features + ['fico_buckets_ll']]\n",
    "y = data[target]\n",
    "X_train_ll, X_test_ll, _, _ = train_test_split(X_ll, y, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e062b-7bb3-4696-9ad4-1edd33672aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build machine learning models (Logistic Regression) \n",
    "model_ll = LogisticRegression(solver='liblinear')\n",
    "model_ll.fit(X_train_ll, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fc84c-83e7-4dc7-91fe-5b69a835cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred_ll = model_ll.predict(X_test_ll)\n",
    "\n",
    "Print model performance metrics for Log-Likelihood method\n",
    "print(\"\\nModel with Log-Likelihood Quantization:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ll))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ll))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed0b2f-a645-4fb9-a6f4-e97196ac9adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
